# machinelearning-IRC-freenode
Community repo for the `##machinelearning` and `##ml-ot` IRC channels on Freenode 

## [Reading Group](ReadingGroup/README.md)
Fortnightly discussion (Sunday 8pm GMT) on a paper/topic of our choosing

## Getting started
* [DeepLearning.TV YouTube playlist](https://www.youtube.com/playlist?list=PLjJh1vlSEYgvZ3ze_4pxKHNh1g5PId36-) -- 17 ~5-min vids, good starter -- introduces the main ideas at anon-technical level.
* [Andrew Ng's ML Coursera course](https://www.youtube.com/view_play_list?p=A89DCFA6ADACE599) -- best beginner course.
* [Nielsen -- Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/index.html) -- online book, recommended for beginners.
* [Hinton's Coursera course: Neural Networks for Machine Learning](https://www.coursera.org/learn/neural-networks) (Youtube playlist [here](https://www.youtube.com/playlist?list=PLoRl3Ht4JOcdU872GhiYWf6jwrk_SNhz9)) -- gets pretty advanced, and much of the later material is fast becoming obsolete (RBM, WakeSleep, DBM, DBN). Nevertheless Hinton is the single biggest contributor to modern ML, and it's worth persevering with.

## ML Software
* http://mloss.org/software/
* http://jmlr.org/mloss/
* [Joseph Misiti's ML links](https://github.com/josephmisiti/awesome-machine-learning)
* http://deeplearning.net/software_links/

## Video Lectures
* http://videolectures.net/Top/Computer_Science/Machine_Learning/

## Books & book-like
* http://deeplearningbook.org/ -- The deep-learning Bible; Dec 2016, Goodfellow, Bengio, Courville (pdf [here](https://github.com/HFTrader/DeepLearningBook pdf))
* [arXiv paper: On the Origin of Deep Learning](https://arxiv.org/abs/1702.07800)
* [arXiv paper: Deep Learning in Neural Networks: An Overview](https://arxiv.org/abs/1404.7828) (link-dense)
* [The Elements of Statistical Learning](http://statweb.stanford.edu/~tibs/ElemStatLearn/)

## Reinforcement Learning
* [David Silver's RL course](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)  [YouTube playlist](https://www.youtube.com/playlist?list=PLMZdRRhAoLnKFxZlmFoFp0uHVvN2PSE9T)
* http://rll.berkeley.edu/deeprlcourse/
* https://www.quora.com/What-are-the-best-books-about-reinforcement-learning

## Communities
* THIS!
* https://stats.stackexchange.com/
* https://datascience.stackexchange.com/
* https://www.reddit.com/r/MachineLearning/

## arXiv (Papers)
* https://arxiv.org/list/stat.ML/recent
* http://arxiv-sanity.com/

## Misc
[Ï€'s scattered links](http://pipad.org/wiki/index.php/Machine_Learning)


# Who are we?
If you are contributing to the channel, please consider private-messaging me an introductory text (freestyle it) & I'll add it here. It would be nice if we have some idea of who is who, who is up to what, etc. Tell us where you are based (so we can figure out your time zone).  Are you using ML for work or play?  What do you use it for?  Do you have a github repo?  Are you at a company/uni?  Care to say?  etc.

* pi- (Oxford UK, freelance coder, https://github.com/p-i-)  
  ML Interests: Primarily the theory.  The new stuff as it comes out (GANs, VAEs, etc.), biologically plausible models (spiking neuron,...), coding in Julia.  
  Relevant skills: IPython / numpy, Matlab, Julia  
  My background is coding, math, DSP. I'm trying to get myself up to speed with modern ML thinking & get a grip on the probabilistic math. I'm keeping an eye on Julia. My goal is to become a digital nomad working with ML.

* pasky (Prague CZ, Github: https://github.com/pasky)  
  ML Interests: Deep architectures, attention models, transfer learning, practice rather than theory  
  In the past, I worked in academia and freelance on a variety of AI / machine learning problems. My main focus was Computer Go (my masters was one of the sort-of-AlphaGo-predecessor programs) and then NLP (question answering and related text understanding problems). Lately I do a lot of vision-like stuff - I co-founded an AI startup Rossum where we are reading invoices using neural networks. I'm a hardcore Keras fan.

* brand0 (Washington, USA, Github: https://github.com/brandonrobertz)
  ML Interests: character-level modeling, text clustering, outlier detection, application to journalism
  I'm an independent researcher with professional experience in investigative journalism and publishing, machine learning, and full-stack development in the tech industry. Currently editing a zine exploring machine learning applied to journalism called [Artificial Informer](http://artificialinformer.com).

 - - - - - - -

# Ideas for this resource:

The IRC ML community is growing -- let's make this a really good ML resource. Together we can nudge it into shape from different angles.

I recommend organic growth -- not being overly hasty to overstructure too soon. That being said, each of these ideas probably wants its own folder + README.md.  GitHub allows relative links so it should be possible to keep everything tidy & build reusable structure.

* **Getting started**  
  Rather than some big unhelpful list of links, maybe we can provide a path to actually getting the first bite on the bobapple.
  
* **Introduce ourselves**  
  Many of us have a homepage somewhere, it's good to see what people are working on.  

* **Detailing a birds eye view of the tree/web of contemporary ML**  
  http://deeplearningbook.org/  
  [On the Origin of Deep Learning](https://arxiv.org/abs/1702.07800)  
  etc.  
  Also linking to landmark papers & relevant blog posts, vids, GitHub repos etc.

* **Wiki-style breakdowns of various techniques e.g. VAEs**  
  Unfortunately GitHub doesn't render equations $a^2+b^2=fail$ (yet?).  

* **Comparison of available frameworks, IDEs, workflows**  
  TensorFlow, Keras, Matlab, Julia, etc.
