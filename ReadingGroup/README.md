# ML-ReadingGroup

Resources (including transcripts) for the (IRC:Freenode) ##machinelearning Reading Group 

NOTE: Reading Group is now every other Sunday! A new paper is chosen by the following Wednesday, which gives everyone 10 days to get up to speed.

<!-- Short URL: https://j.mp/ML-ReadingGrp -->

The scheduled time for the next group discussion is [Sunday 7 May 2017 @ 8pm UTC](https://www.wolframalpha.com/input/?i=next+Sunday+8+pm+UTC).


## Next discussion: VAE (Variational AutoEncoders) (Sunday 7 May 2017 @ 8pm UTC)
* Main paper: [Auto-Encoding Variational Bayes](https://arxiv.org/abs/1312.6114)  

Resources:
* [Doersch Jun '16: Tutorial on Variational Autoencoders](https://arxiv.org/abs/1606.05908)  
* Variational Autoencoders (in Prose and Code) by Miriam.
  * [PART 1: Introducing Variational Autoencoders (in Prose and Code) by Miriam](http://blog.fastforwardlabs.com/2016/08/12/introducing-variational-autoencoders-in-prose-and.html)
  * [PART 2: Under the Hood of the Variational Autoencoder (in Prose and Code) by Miriam](http://blog.fastforwardlabs.com/2016/08/22/under-the-hood-of-the-variational-autoencoder-in.html).
* Variational Autoencoders by Vu Pham
  * [Variational Autoencoders 1: Overview](https://phvu.net/2017/02/26/variational-autoencoders-1-overview/)
  * [Variational Autoencoders 2: Maths](https://phvu.net/2017/04/02/variational-autoencoders-2-maths/)
  * [Variational Autoencoders 3: Training, Inference and comparison with other models](https://phvu.net/2017/04/02/variational-autoencoders-3-training-inference-and-comparison-with-other-models/)

## Candidates for future discussions:
* [DNC](https://github.com/deepmind/dnc) (Differentiable Neural Computer)
* Learning without Backpropagation http://www.breloff.com/no-backprop/
* [Overcoming catastrophic forgetting in neural networks](https://arxiv.org/abs/1612.00796)
* [Semi-Supervised Learning with Ladder Networks](https://arxiv.org/abs/1507.02672)
* [The Reactor: A Sample-Efficient Actor-Critic Architecture](https://arxiv.org/abs/1704.04651) (15 Apr '17)

## Past discussions:
* 2017.04.16 Hinton's 2006 "Reducing the Dimensionality of Data with Neural Networks" [paper](https://www.cs.toronto.edu/~hinton/science.pdf)  
  [log](logs/2017.04.16)  

* 2017.04.23 GANs: Goodfellow's 2014 "Generative Adversarial Networks" [paper](https://arxiv.org/abs/1406.2661)  
  [log](logs/2017.04.23)  
  Resources:
     - [NIPS 2016 Tutorial: Generative Adversarial Networks](https://arxiv.org/abs/1701.00160)
     - http://blog.evjang.com/2016/06/generative-adversarial-nets-in.html
     - [Goodfellow @ NIPS '16 (+6 other vids on GAN)](https://www.youtube.com/watch?v=RvgYvHyT15E&list=PLJscN9YDD1buxCitmej1pjJkR5PMhenTF)     
     - Stacked GANs:  
        - [Stacked Generative Adversarial Networks](https://arxiv.org/abs/1612.04357) <-- Can anyone grok fig.1??  
        - [StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks](https://arxiv.org/abs/1612.03242)  
        ^ note both papers were submitted within three days one another (10/13 Dec '16)  

