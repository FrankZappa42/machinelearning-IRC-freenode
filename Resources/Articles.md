Contents:
<!-- TOC can be generated manually using https://ecotrust-canada.github.io/markdown-toc/ -->
- [Neural networks](#neural-networks)
- [Deep learning](#deep-learning)
  * [Overview](#overview)
  * [Theory](#theory)
  * [Analysis](#analysis)
  * [Limitations](#limitations)
  * [Practice](#practice)
  * [Software](#software)
    + [Comparison](#comparison)
    + [TensorFlow](#tensorflow)
- [Deep convolutional networks](#deep-convolutional-networks)
  * [Overview](#overview-1)
  * [Theory](#theory-1)
  * [Analysis](#analysis-1)
- [Deep reinforcement learning](#deep-reinforcement-learning)
  * [Overview](#overview-2)
  * [Analysis](#analysis-2)

## Neural networks
* [Hacker's guide to Neural Networks](http://karpathy.github.io/neuralnets/)
* [arXiv] [Neural Networks for Beginners. A fast implementation in Matlab, Torch, TensorFlow (2017)](https://arxiv.org/abs/1703.05298)
* [arXiv] [Understanding Convolutional Neural Networks (2016)](https://arxiv.org/abs/1605.09081)

## Deep learning
### Overview
* [Deep learning (2015)](http://www.nature.com/nature/journal/v521/n7553/abs/nature14539.html) ([pdf](http://pages.cs.wisc.edu/~dyer/cs540/handouts/deep-learning-nature2015.pdf))
* [arXiv] [Deep Learning in Neural Networks: An Overview (2014)](https://arxiv.org/abs/1404.7828) (link-dense)
* [arXiv] [On the Origin of Deep Learning (2017)](https://arxiv.org/abs/1702.07800)
### Theory
* [arXiv] [Understanding deep learning requires rethinking generalization (2017)](https://arxiv.org/abs/1611.03530)
* [arXiv] [On Generalization and Regularization in Deep Learning (2017)](https://arxiv.org/abs/1704.01312)
* [arXiv] [Why does deep and cheap learning work so well? (2017)](https://arxiv.org/abs/1608.08225v2)
* [arXiv] [Why and When Can Deep -- but Not Shallow -- Networks Avoid the Curse of Dimensionality: a Review (2017)](https://arxiv.org/abs/1611.00740)
* [arXiv] [Geometry of Optimization and Implicit Regularization in Deep Learning (2017)](https://arxiv.org/abs/1705.03071)
* [arXiv] [Why does Deep Learning work? - A perspective from Group Theory (2015)](https://arxiv.org/abs/1412.6621)
#### Analysis
* [arXiv] [Opening the Black Box of Deep Neural Networks via Information (2017)](https://arxiv.org/abs/1703.00810)
#### Limitations
* [arXiv] [Failures of Gradient-Based Deep Learning (2017)](https://arxiv.org/abs/1703.07950)
### Practice
* [arXiv] [Fathom: Reference Workloads for Modern Deep Learning Methods (2016)](https://arxiv.org/abs/1608.06581)
* [The Black Magic of Deep Learning - Tips and Tricks for the practitioner (2017)](https://nmarkou.blogspot.fr/2017/02/the-black-magic-of-deep-learning-tips.html)
### Software
#### Comparison
* [arXiv] [Comparative Study of Deep Learning Software Frameworks (2016)](https://arxiv.org/abs/1511.06435)
* [arXiv] [Benchmarking State-of-the-Art Deep Learning Software Tools (2017)](https://arxiv.org/abs/1608.07249)
#### TensorFlow
* [arXiv] [TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems (2016)](https://arxiv.org/abs/1603.04467)
* [arXiv] [A Tour of TensorFlow (2016)](https://arxiv.org/abs/1610.01178)
* [arXiv] [Should I use TensorFlow (2016)](https://arxiv.org/abs/1611.08903)

## Deep convolutional networks
### Overview
* [arXiv] [Understanding Deep Convolutional Networks (2016)](https://arxiv.org/abs/1601.04920)
### Theory
* [arXiv] [Do Deep Convolutional Nets Really Need to be Deep and Convolutional? (2017)](https://arxiv.org/abs/1603.05691)
* [arXiv] [Analysis and Design of Convolutional Networks via Hierarchical Tensor Decompositions (2017)](https://arxiv.org/abs/1705.02302)
### Analysis
* [arXiv] [Towards Better Analysis of Deep Convolutional Neural Networks (2016)](https://arxiv.org/abs/1604.07043)

## Deep reinforcement learning
### Overview
* [arXiv] [Deep Reinforcement Learning: An Overview (2017)](https://arxiv.org/abs/1701.07274)
### Analysis
* [arXiv] [Graying the black box: Understanding DQNs (2017)](https://arxiv.org/abs/1602.02658)
